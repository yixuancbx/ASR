# 训练速度优化指南

## 当前问题
训练和验证一轮需要7小时，速度过慢。

## 已实施的优化

### 1. 混合精度训练 (AMP) ✅
- 使用 `torch.cuda.amp` 进行混合精度训练
- **预期加速**: 1.5-2倍
- **内存节省**: 约30-50%

### 2. 数据加载优化 ✅
- 增加 `num_workers` 从2到4
- 减少GPU缓存清理频率（从每20个batch改为每100个batch）
- 减少进度条更新频率

### 3. 损失函数优化 ✅
- 类内聚合损失：限制每个说话人最多使用10个样本计算
- 减少计算复杂度

### 4. 验证频率优化 ✅
- 添加 `val_interval` 参数，可以每N个epoch验证一次
- 默认每2个epoch验证一次

### 5. 批次大小优化 ✅
- 增加 `batch_size` 从2到4（如果内存允许）

## 进一步优化建议

### 方案1：增加batch_size（最有效）

如果GPU内存允许，可以进一步增加batch_size：

```json
{
  "training": {
    "batch_size": 8  // 或更大
  }
}
```

**预期加速**: 2-3倍（因为GPU利用率更高）

### 方案2：增加num_workers

```json
{
  "data": {
    "num_workers": 8  // 根据CPU核心数调整
  }
}
```

**注意**: 不要超过CPU核心数

### 方案3：减少验证频率

```json
{
  "training": {
    "val_interval": 5  // 每5个epoch验证一次
  }
}
```

### 方案4：优化全局注意力（如果序列很长）

如果 `seq_length` 很大（>8000），全局时序注意力的计算复杂度是O(T²)，可以考虑：
- 使用线性注意力
- 减少注意力头数
- 使用局部注意力窗口

### 方案5：使用数据预加载

如果数据集在机械硬盘上，考虑：
- 将数据集移到SSD
- 使用数据预加载和缓存

### 方案6：减少seq_length

如果当前使用4000（0.25秒），可以尝试：
- 使用更短的片段（如2000，0.125秒）
- 在训练后期再使用长片段

## 性能对比

| 优化项 | 预期加速 | 实施难度 |
|--------|---------|---------|
| 混合精度训练 | 1.5-2x | ✅ 已实施 |
| 增加batch_size (2→4) | 1.5-2x | ✅ 已实施 |
| 增加num_workers (2→4) | 1.2-1.5x | ✅ 已实施 |
| 减少验证频率 | 1.2-1.5x | ✅ 已实施 |
| 优化损失函数 | 1.1-1.2x | ✅ 已实施 |
| 减少GPU清理频率 | 1.1-1.2x | ✅ 已实施 |

**总体预期加速**: 3-5倍

## 当前配置（优化后）

```json
{
  "training": {
    "batch_size": 4,
    "use_amp": true,
    "val_interval": 2
  },
  "data": {
    "num_workers": 4
  }
}
```

## 监控训练速度

训练时会显示：
- 每个batch的处理时间
- 内存使用情况
- 如果速度仍然慢，可以进一步调整参数

## 如果仍然很慢

1. **检查数据加载瓶颈**：
   - 数据集是否在SSD上？
   - 是否有其他进程占用I/O？

2. **检查GPU利用率**：
   ```bash
   nvidia-smi -l 1
   ```
   如果GPU利用率<80%，说明有瓶颈

3. **进一步增加batch_size**（如果内存允许）

4. **考虑使用多GPU训练**（如果有多个GPU）


